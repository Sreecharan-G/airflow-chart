# Default values for airflow.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

airflow:
  # group of airflow user
  gid: 50000

  # Airflow home directory; Used for mount paths
  airflowHome: "/usr/local/airflow"

  # Airflow executor
  # Options: SequentialExecutor, LocalExecutor, CeleryExecutor, KubernetesExecutor
  executor: "KubernetesExecutor"

  # Airflow version
  airflowVersion: 2.0.0

  # Default airflow repository
  defaultAirflowRepository: quay.io/astronomer/ap-airflow

  # Default airflow tag to deploy
  defaultAirflowTag: 2.0.0-buster

  # Astronomer Airflow images
  images:
    airflow:
      repository: quay.io/astronomer/ap-airflow
      tag: ~
      pullPolicy: IfNotPresent
    statsd:
      repository: quay.io/astronomer/ap-statsd-exporter
      tag: 0.18.0
      pullPolicy: IfNotPresent
    redis:
      repository: quay.io/astronomer/ap-redis
      tag: 6.2.1
      pullPolicy: IfNotPresent
    pgbouncer:
      repository: quay.io/astronomer/ap-pgbouncer
      tag: 1.8.1
      pullPolicy: IfNotPresent
    pgbouncerExporter:
      repository: quay.io/astronomer/ap-pgbouncer-exporter
      tag: 0.9.2
      pullPolicy: IfNotPresent

  # Airflow scheduler settings
  scheduler:
    livenessProbe:
      timeoutSeconds: 30
    strategy:
      type: Recreate
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: component
                    operator: In
                    values:
                      - scheduler
              topologyKey: "kubernetes.io/hostname"

  # Airflow webserver settings
  webserver:
    allowPodLogReading: false
    webserverConfig: |
      import os
      from airflow import configuration as conf
      from flask_appbuilder.security.manager import AUTH_REMOTE_USER
      basedir = os.path.abspath(os.path.dirname(__file__))

      # The SQLAlchemy connection string.
      SQLALCHEMY_DATABASE_URI = conf.get('core', 'SQL_ALCHEMY_CONN')

      # Flask-WTF flag for CSRF
      CSRF_ENABLED = True

      # ----------------------------------------------------
      # AUTHENTICATION CONFIG
      # ----------------------------------------------------
      # TODO: Need a new way to toggle this (useAstroSecurityManager)
      {{- if .Values.webserver.jwtSigningCertificateSecretName }}
      AUTH_TYPE = AUTH_REMOTE_USER

      from astronomer.flask_appbuilder.security import AirflowAstroSecurityManager
      SECURITY_MANAGER_CLASS = AirflowAstroSecurityManager
      {{- end }}

  # Airflow worker settings
  workers:
    persistence:
      # Enable persistent volumes
      enabled: false

  # Pgbouncer settings
  pgbouncer:
    # Pool sizes
    metadataPoolSize: 3
    resultBackendPoolSize: 2

  # Elasticsearch logging configuration
  elasticsearch:
    connection:
      scheme: http

  airflowLocalSettings: |
    {{- if semverCompare "<1.10.12" .Values.airflowVersion }}

    from airflow.contrib.kubernetes.pod import Pod
    from airflow.configuration import conf

    def pod_mutation_hook(pod: Pod):

        extra_labels = {
            "kubernetes_executor": "False",
            "kubernetes_pod_operator": "False"
        }

        if 'airflow-worker' in pod.labels.keys() or \
                conf.get('core', 'EXECUTOR') == "KubernetesExecutor":
            extra_labels["kubernetes_executor"] = "True"
        else:
            extra_labels["kubernetes_pod_operator"] = "True"

        pod.labels.update(extra_labels)
        pod.tolerations += {{ toJson .Values.podMutation.tolerations }}
        pod.affinity.update({{ toJson .Values.podMutation.affinity }})
    {{- else }}
    from kubernetes.client import models as k8s
    from airflow.configuration import conf

    def pod_mutation_hook(pod: k8s.V1Pod):

        extra_labels = {
            "kubernetes_executor": "False",
            "kubernetes_pod_operator": "False"
        }

        if 'airflow-worker' in pod.metadata.labels.keys() or \
                conf.get('core', 'EXECUTOR') == "KubernetesExecutor":
            extra_labels["kubernetes_executor"] = "True"
        else:
            extra_labels["kubernetes_pod_operator"] = "True"

        pod.metadata.labels.update(extra_labels)
        if pod.spec.tolerations:
            pod.spec.tolerations += {{ toJson .Values.podMutation.tolerations }}
        else:
            pod.spec.tolerations = {{ toJson .Values.podMutation.tolerations }}

        if pod.spec.affinity:
            pod.spec.affinity = pod.spec.affinity.to_dict().update({{ toJson .Values.podMutation.affinity }})
        else:
            pod.spec.affinity = {{ toJson .Values.podMutation.affinity }}

    {{- end }}

  # Config Settings for pod_mutation_hook
  podMutation:
    # Tolerations provided here would be applied using pod_mutation_hook
    # So any pods spun up using KubernetesExecutor or KubernetesPodOperator will contain these tolerations.
    tolerations: []
    #  - key: "dynamic-pods"
    #    operator: "Equal"
    #    value: "true"
    #    effect: "NoSchedule"

    # Pods spun up would land in the node that matches the affinity
    affinity: {}
    #  nodeAffinity:
    #    requiredDuringSchedulingIgnoredDuringExecution:
    #      nodeSelectorTerms:
    #        - matchExpressions:
    #            - key: "astronomer.io/dynamic-pods"
    #              operator: In
    #              values:
    #                - "true"

  migrateDatabaseJob:
    annotations:
      "sidecar.istio.io/inject": "false"

  config:
    operators:
      default_queue: celery
    celery: # compat
      default_queue: celery
    webserver:
      expose_config: True
      base_url: '{{ .Values.ingress.enabled | ternary (printf "https://%s/%s/airflow" (include "deployments_subdomain" .) .Release.Name) "http://localhost:8080"}}'
    elasticsearch:
      elasticsearch_write_stdout: True
    kubernetes:
      dags_in_image: True
    # TODO: Make this work
    #astronomer:
    #  {{- if .Values.webserver.jwtSigningCertificateSecretName }}
    #  jwt_signing_cert = {{ template "airflow_webserver_jwt_cert_path" . }}
    #  jwt_audience = {{ printf "%s/%s" ( include "deployments_subdomain" . ) .Release.Name }}
    #  {{- end }}

# Airflow Worker Config
# TODO: should this be under airflow.workers just for consistency?
# TODO: does the platform actually enable this in some cases?
workers:
  # Apply a HorizontalPodAutoscaler
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilization: 80
    targetMemoryUtilization: 80

# Enable security context constraints required for OpenShift
sccEnabled: false

# Extra objects to deploy (these are passed through `tpl`)
extraObjects: []

# Ingress configuration
ingress:
  # Enable ingress resource
  enabled: false

  # Enable for cert-manager or kube-lego
  acme: false

  # Name of tls secret to use on ingress
  tlsSecretName: ~

  # Annotations always injected when configuring webserver Ingress object
  webserverAnnotations: {}

  # Annotations always injected when configuring Flower Ingress object
  flowerAnnotations: {}

  # Base domain for ingress vhosts
  baseDomain: ~

  # Enable platform authentication
  auth:
    enabled: true

#####################################
# Leftovers

# Extra annotations to apply to Create user job
#createUserJobAnnotations: {}
# Moved to createUserJob.annotations

# Extra annotations to apply to run migrations job
#runMigrationsJobAnnotations: {}
# Moved to migrateDatabaseJob.annotations

# Extra annotations to apply to service accounts
#serviceAccountAnnotations: {}
# Moved to respective sections: e.g. scheduler.serviceAccount.annotations

# Enable RBAC (default on most clusters these days)
#rbacEnabled: true
# Moved to rbac.create (same default)

# Pass a secret name here to mount all keys as environment variables in
# the Airflow pods.
#mountAllFromSecretName: ~
# Moved to extraEnvFrom (same default, accepts different value)

# Airflow Worker Config
#workers:
#  # Attach additional volume to celery workers (such as a shared file system)
#  #additionalVolume:
#  #  enabled: false
#  #  volumeMode: ~
#  #  accessMode: ~
#  #  capacity: ~
#  #  storageClassName:
#  #  mountPath: ~
#  #  volumePlugin: {}
#  # Moved to workers.extraVolumes and workers.extraVolumeMounts (same default, accepts different value)

# Airflow scheduler settings
#scheduler:
#  # This setting can overwrite
#  # podMutation settings - be sure
#  # to reference the default if you
#  # are making use of those settings.
#  #airflowLocalSettings: ~
#  # Moved to airflowLocalSettings (same default)

# Airflow webserver settings
#webserver:
#  # Secret that contains the cert to verify JWTs
#  #jwtSigningCertificateSecretName: ~
#  # Moved to webserver.extraVolumes and webserver.extraVolumeMounts and new flag (useAstroSecurityManager)

# Pgbouncer settings
#pgbouncer:
#  networkPolicies:
#    enabled: true
#    # TODO: Do we really need a flag to disable just the networkpolicy for pgbouncer?
#
#  # ability to add more custom pgbouncer configuration
#  extraIniDatabaseMetatdata: ""
#  Moved to pgbouncer.extraIniMetadata
#  extraIniDatabaseResultBackend: ""
#  Moved to pgbouncer.extraIniResultBackend
#  extraIniPgbouncerConfig: ""
#  Moved to pgbouncer.extraIni

# This block contains settings strictly used to integrate into the Astronomer platform.
# This is what allows for integration into platform ingress, network policies, metrics collection, etc.
# This chart is completely deployable without specifying these values.
platform:
  release: ~
  workspace: ""
  # No "easy" answer right now:
  #flower:
  #  service.extraAnnotations:
  #    astronomer.io/platform-release: {{ .Values.platform.release }}
  #  extraNetworkPolicies:
  #    - namespaceSelector: {}
  #      podSelector:
  #        matchLabels:
  #          tier: nginx
  #          component: ingress-controller
  #          release: { { .Values.platform.release } }
  # If we template extraAnnotations and extraNetworkPolicies, maybe we can make this a little nicer.
